{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014cca03-a2bd-4f14-b3f2-4785b64c4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DGLBACKEND'] = 'pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4f72df-fb93-40ce-b0a1-923ec2918cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "class Logger():\n",
    "    def __init__(self, filename, is_debug, path='/root/autodl-fs/model/mmssl_log/'):\n",
    "        self.filename = filename\n",
    "        self.path = path\n",
    "        self.log_ = not is_debug\n",
    "    def logging(self, s):\n",
    "        s = str(s)\n",
    "        print(datetime.now().strftime('%Y-%m-%d %H:%M: '), s)\n",
    "        if self.log_:\n",
    "            with open(os.path.join(os.path.join(self.path, self.filename)), 'a+') as f_log:\n",
    "                f_log.write(str(datetime.now().strftime('%Y-%m-%d %H:%M:  ')) + s + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e674eee7-eddc-43ad-b9fd-b8acaa60410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def recall(rank, ground_truth, N):\n",
    "    return len(set(rank[:N]) & set(ground_truth)) / float(len(set(ground_truth)))\n",
    "\n",
    "\n",
    "def precision_at_k(r, k):\n",
    "    \"\"\"Score is precision @ k\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "    Returns:\n",
    "        Precision @ k\n",
    "    Raises:\n",
    "        ValueError: len(r) must be >= k\n",
    "    \"\"\"\n",
    "    assert k >= 1\n",
    "    r = np.asarray(r)[:k]\n",
    "    return np.mean(r)\n",
    "\n",
    "\n",
    "def average_precision(r,cut):\n",
    "    \"\"\"Score is average precision (area under PR curve)\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "    Returns:\n",
    "        Average precision\n",
    "    \"\"\"\n",
    "    r = np.asarray(r)\n",
    "    out = [precision_at_k(r, k + 1) for k in range(cut) if r[k]]\n",
    "    if not out:\n",
    "        return 0.\n",
    "    return np.sum(out)/float(min(cut, np.sum(r)))\n",
    "\n",
    "\n",
    "def mean_average_precision(rs):\n",
    "    \"\"\"Score is mean average precision\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "    Returns:\n",
    "        Mean average precision\n",
    "    \"\"\"\n",
    "    return np.mean([average_precision(r) for r in rs])\n",
    "\n",
    "\n",
    "def dcg_at_k(r, k, method=1):\n",
    "    \"\"\"Score is discounted cumulative gain (dcg)\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "    Returns:\n",
    "        Discounted cumulative gain\n",
    "    \"\"\"\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k, method=1):\n",
    "    \"\"\"Score is normalized discounted cumulative gain (ndcg)\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "    Returns:\n",
    "        Normalized discounted cumulative gain\n",
    "    \"\"\"\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max\n",
    "\n",
    "\n",
    "def recall_at_k(r, k, all_pos_num):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if all_pos_num == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.sum(r) / all_pos_num\n",
    "\n",
    "\n",
    "def hit_at_k(r, k):\n",
    "    r = np.array(r)[:k]\n",
    "    if np.sum(r) > 0:\n",
    "        return 1.\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "def mrr_at_k(r, k):\n",
    "    r = np.array(r)[:k]\n",
    "    #print(r)\n",
    "    if np.sum(r) > 0:\n",
    "        #print(1/(np.where(r==1.0)[0]+1).astype(float)[0])\n",
    "        return 1/(np.where(r==1.0)[0]+1).astype(float)[0]\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def F1(pre, rec):\n",
    "    if pre + rec > 0:\n",
    "        return (2.0 * pre * rec) / (pre + rec)\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "def auc(ground_truth, prediction):\n",
    "    try:\n",
    "        res = roc_auc_score(y_true=ground_truth, y_score=prediction)\n",
    "    except Exception:\n",
    "        res = 0.\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90065cb7-d99d-460b-a1d8-eae9260fb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    class Args:\n",
    "        p=0\n",
    "        dataset = 'beauty'\n",
    "        verbose = 5\n",
    "        core = 5\n",
    "        lambda_coeff = 0.9\n",
    "        early_stopping_patience = 7\n",
    "        layers = 1\n",
    "        mess_dropout = '[0.1, 0.1]'\n",
    "        sparse = 1\n",
    "        test_flag = 'part'\n",
    "        metapath_threshold = 2\n",
    "        sc = 1.0\n",
    "        ssl_c_rate = 1.3\n",
    "        ssl_s_rate = 0.8\n",
    "        g_rate = 0.000029\n",
    "        sample_num = 1\n",
    "        sample_num_neg = 1\n",
    "        sample_num_ii = 8\n",
    "        sample_num_co = 2\n",
    "        mask_rate = 0.75\n",
    "        gss_rate = 0.85\n",
    "        anchor_rate = 0.75\n",
    "        feat_reg_decay = 1e-5\n",
    "        ad1_rate = 0.2\n",
    "        ad2_rate = 0.2\n",
    "        ad_sampNum = 1\n",
    "        ad_topk_multi_num = 100\n",
    "        fake_gene_rate = 0.0001\n",
    "        ID_layers = 1\n",
    "        reward_rate = 1\n",
    "        G_embed_size = 64\n",
    "        model_num = 2\n",
    "        negrate = 0.01\n",
    "        cis = 25\n",
    "        confidence = 0.5\n",
    "        ii_it = 15\n",
    "        isload = False\n",
    "        isJustTest = False\n",
    "        loadModelPath = '/home/ww/Code/work3/BSTRec/Model/retailrocket/for_meta_hidden_dim_dim__8_retailrocket_2021_07_10__18_35_32_lr_0.0003_reg_0.01_batch_size_1024_gnn_layer_[16,16,16].pth'\n",
    "        title = \"try_to_draw_line\"\n",
    "        data_path = './'\n",
    "        seed = 123\n",
    "        epoch = 1000\n",
    "        batch_size = 128\n",
    "        embed_size = 64\n",
    "        D_lr = 3e-4\n",
    "        topk = 10\n",
    "        cf_model = 'slmrec'\n",
    "        debug = False\n",
    "        cl_rate = 0.03\n",
    "        norm_type = 'sym'\n",
    "        gpu_id = 0\n",
    "        Ks = '[10, 20, 50, 5]'\n",
    "        regs = '[1e-5,1e-5,1e-2]'\n",
    "        lr = 0.00055\n",
    "        emm = 1e-3\n",
    "        L2_alpha = 1e-3\n",
    "        weight_decay = 1e-4\n",
    "        drop_rate = 0.2\n",
    "        model_cat_rate = 0.55\n",
    "        gnn_cat_rate = 0.55\n",
    "        id_cat_rate = 0.36\n",
    "        id_cat_rate1 = 0.36\n",
    "        head_num = 4\n",
    "        dgl_nei_num = 8\n",
    "        weight_size = '[64, 64]'\n",
    "        G_rate = 0.0001\n",
    "        G_drop1 = 0.31\n",
    "        G_drop2 = 0.5\n",
    "        gp_rate = 1\n",
    "        real_data_tau = 0.005\n",
    "        ui_pre_scale = 100\n",
    "        T = 1\n",
    "        tau = 0.5\n",
    "        geneGraph_rate = 0.1\n",
    "        geneGraph_rate_pos = 2\n",
    "        geneGraph_rate_neg = -1\n",
    "        m_topk_rate = 0.0001\n",
    "        log_log_scale = 0.00001\n",
    "        point = ''\n",
    "        test_flag = 'part'\n",
    "        shuffle='text'\n",
    "    return Args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbecf7c0-b1a8-4f5a-8166-88faba81a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd\n",
    "import scipy.sparse as sp\n",
    "from time import time\n",
    "import json\n",
    "#from utility.parser import parse_args\n",
    "args = parse_args()\n",
    "\n",
    "class Data(object):\n",
    "    def __init__(self, path, batch_size):\n",
    "        self.path = path + '%d-core' % args.core\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        train_file = path + '/%d-core/train.json' % (args.core)\n",
    "        val_file = path + '/%d-core/val.json' % (args.core)\n",
    "        test_file = path + '/%d-core/test.json'  % (args.core)\n",
    "\n",
    "        #get number of users and items\n",
    "        self.n_users, self.n_items = 0, 0\n",
    "        self.n_train, self.n_test = 0, 0\n",
    "        self.neg_pools = {}\n",
    "\n",
    "        self.exist_users = []\n",
    "        \n",
    "\n",
    "        \n",
    "        train = json.load(open(train_file))\n",
    "        test = json.load(open(test_file))\n",
    "        val = json.load(open(val_file))\n",
    "        \n",
    "        for uid, items in train.items():\n",
    "            if len(items) == 0:\n",
    "                continue\n",
    "            uid = int(uid)\n",
    "            self.exist_users.append(uid)\n",
    "            self.n_items = max(self.n_items, max(items))\n",
    "            self.n_users = max(self.n_users, uid)\n",
    "            self.n_train += len(items)\n",
    "\n",
    "        for uid, items in test.items():\n",
    "            uid = int(uid)\n",
    "            try:\n",
    "                self.n_items = max(self.n_items, max(items))\n",
    "                self.n_test += len(items)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        for uid, items in val.items():\n",
    "            uid = int(uid)\n",
    "            try:\n",
    "                self.n_items = max(self.n_items, max(items))\n",
    "                self.n_val += len(items)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        self.n_items += 1\n",
    "        self.n_users += 1\n",
    "\n",
    "        self.print_statistics()\n",
    "\n",
    "        self.R = sp.dok_matrix((self.n_users, self.n_items), dtype=np.float32)\n",
    "        self.R_Item_Interacts = sp.dok_matrix((self.n_items, self.n_items), dtype=np.float32)\n",
    "\n",
    "        self.train_items, self.test_set, self.val_set = {}, {}, {}\n",
    "        for uid, train_items in train.items():\n",
    "            if len(train_items) == 0:\n",
    "                continue\n",
    "            uid = int(uid)\n",
    "            for idx, i in enumerate(train_items):\n",
    "                self.R[uid, i] = 1.\n",
    "\n",
    "            self.train_items[uid] = train_items\n",
    "\n",
    "        self.my_test_set=[]\n",
    "        for uid, test_items in test.items():\n",
    "            uid = int(uid)\n",
    "            if len(test_items) == 0:\n",
    "                continue\n",
    "            for i in test_items:\n",
    "                self.my_test_set.append([uid,i])\n",
    "            try:\n",
    "                self.test_set[uid] = test_items\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        for uid, val_items in val.items():\n",
    "            uid = int(uid)\n",
    "            if len(val_items) == 0:\n",
    "                continue\n",
    "            try:\n",
    "                self.val_set[uid] = val_items\n",
    "            except:\n",
    "                continue            \n",
    "\n",
    "    def get_adj_mat(self):\n",
    "        try:\n",
    "            t1 = time()\n",
    "            adj_mat = sp.load_npz(self.path + '/s_adj_mat.npz')\n",
    "            norm_adj_mat = sp.load_npz(self.path + '/s_norm_adj_mat.npz')\n",
    "            mean_adj_mat = sp.load_npz(self.path + '/s_mean_adj_mat.npz')\n",
    "            print('already load adj matrix', adj_mat.shape, time() - t1)\n",
    "\n",
    "        except Exception:\n",
    "            adj_mat, norm_adj_mat, mean_adj_mat = self.create_adj_mat()\n",
    "            sp.save_npz(self.path + '/s_adj_mat.npz', adj_mat)\n",
    "            sp.save_npz(self.path + '/s_norm_adj_mat.npz', norm_adj_mat)\n",
    "            sp.save_npz(self.path + '/s_mean_adj_mat.npz', mean_adj_mat)\n",
    "        return adj_mat, norm_adj_mat, mean_adj_mat\n",
    "\n",
    "    def create_adj_mat(self):\n",
    "        t1 = time()\n",
    "        adj_mat = sp.dok_matrix((self.n_users + self.n_items, self.n_users + self.n_items), dtype=np.float32)\n",
    "        adj_mat = adj_mat.tolil()\n",
    "        R = self.R.tolil()\n",
    "\n",
    "        adj_mat[:self.n_users, self.n_users:] = R\n",
    "        adj_mat[self.n_users:, :self.n_users] = R.T\n",
    "        adj_mat = adj_mat.todok()\n",
    "        print('already create adjacency matrix', adj_mat.shape, time() - t1)\n",
    "\n",
    "        t2 = time()\n",
    "\n",
    "        def normalized_adj_single(adj):\n",
    "            rowsum = np.array(adj.sum(1))\n",
    "\n",
    "            d_inv = np.power(rowsum, -1).flatten()\n",
    "            d_inv[np.isinf(d_inv)] = 0.\n",
    "            d_mat_inv = sp.diags(d_inv)\n",
    "\n",
    "            norm_adj = d_mat_inv.dot(adj)\n",
    "            # norm_adj = adj.dot(d_mat_inv)\n",
    "            print('generate single-normalized adjacency matrix.')\n",
    "            return norm_adj.tocoo()\n",
    "\n",
    "        def get_D_inv(adj):\n",
    "            rowsum = np.array(adj.sum(1))\n",
    "\n",
    "            d_inv = np.power(rowsum, -1).flatten()\n",
    "            d_inv[np.isinf(d_inv)] = 0.\n",
    "            d_mat_inv = sp.diags(d_inv)\n",
    "            return d_mat_inv\n",
    "\n",
    "        def check_adj_if_equal(adj):\n",
    "            dense_A = np.array(adj.todense())\n",
    "            degree = np.sum(dense_A, axis=1, keepdims=False)\n",
    "\n",
    "            temp = np.dot(np.diag(np.power(degree, -1)), dense_A)\n",
    "            print('check normalized adjacency matrix whether equal to this laplacian matrix.')\n",
    "            return temp\n",
    "\n",
    "        norm_adj_mat = normalized_adj_single(adj_mat + sp.eye(adj_mat.shape[0]))\n",
    "        mean_adj_mat = normalized_adj_single(adj_mat)\n",
    "\n",
    "        print('already normalize adjacency matrix', time() - t2)\n",
    "        return adj_mat.tocsr(), norm_adj_mat.tocsr(), mean_adj_mat.tocsr()\n",
    "\n",
    "\n",
    "    def sample(self):\n",
    "        if self.batch_size <= self.n_users:\n",
    "            users = rd.sample(self.exist_users, self.batch_size)\n",
    "        else:\n",
    "            users = [rd.choice(self.exist_users) for _ in range(self.batch_size)]\n",
    "        # users = self.exist_users[:]\n",
    "\n",
    "        def sample_pos_items_for_u(u, num):\n",
    "            pos_items = self.train_items[u]\n",
    "            n_pos_items = len(pos_items)\n",
    "            pos_batch = []\n",
    "            while True:\n",
    "                if len(pos_batch) == num: break\n",
    "                pos_id = np.random.randint(low=0, high=n_pos_items, size=1)[0]\n",
    "                pos_i_id = pos_items[pos_id]\n",
    "\n",
    "                if pos_i_id not in pos_batch:\n",
    "                    pos_batch.append(pos_i_id)\n",
    "            return pos_batch\n",
    "\n",
    "        def sample_neg_items_for_u(u, num):\n",
    "            neg_items = []\n",
    "            while True:\n",
    "                if len(neg_items) == num: break\n",
    "                neg_id = np.random.randint(low=0, high=self.n_items, size=1)[0]\n",
    "                if neg_id not in self.train_items[u] and neg_id not in neg_items:\n",
    "                    neg_items.append(neg_id)\n",
    "            return neg_items\n",
    "\n",
    "        def sample_neg_items_for_u_from_pools(u, num):\n",
    "            neg_items = list(set(self.neg_pools[u]) - set(self.train_items[u]))\n",
    "            return rd.sample(neg_items, num)\n",
    "\n",
    "        pos_items, neg_items = [], []\n",
    "        for u in users:\n",
    "            pos_items += sample_pos_items_for_u(u, 1)\n",
    "            neg_items += sample_neg_items_for_u(u, 1)\n",
    "            # neg_items += sample_neg_items_for_u(u, 3)\n",
    "        return users, pos_items, neg_items\n",
    "        \n",
    "\n",
    "    def print_statistics(self):\n",
    "        print('n_users=%d, n_items=%d' % (self.n_users, self.n_items))\n",
    "        print('n_interactions=%d' % (self.n_train + self.n_test))\n",
    "        print('n_train=%d, n_test=%d, sparsity=%.5f' % (self.n_train, self.n_test, (self.n_train + self.n_test)/(self.n_users * self.n_items)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cdc9eb-3695-4191-9860-86afd02d9eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import utility.metrics as metrics\n",
    "#from utility.parser import parse_args\n",
    "#from utility.load_data import Data\n",
    "import multiprocessing\n",
    "import heapq\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "cores = multiprocessing.cpu_count() // 5\n",
    "\n",
    "args = parse_args()\n",
    "Ks = eval(args.Ks)\n",
    "print(args.data_path + args.dataset)\n",
    "data_generator = Data(path=args.data_path + args.dataset, batch_size=args.batch_size)\n",
    "USR_NUM, ITEM_NUM = data_generator.n_users, data_generator.n_items\n",
    "N_TRAIN, N_TEST = data_generator.n_train, data_generator.n_test\n",
    "BATCH_SIZE = args.batch_size\n",
    "\n",
    "def ranklist_by_heapq(user_pos_test, test_items, rating, Ks):\n",
    "    item_score = {}\n",
    "    for i in test_items:\n",
    "        item_score[i] = rating[i]\n",
    "\n",
    "    K_max = max(Ks)\n",
    "    K_max_item_score = heapq.nlargest(K_max, item_score, key=item_score.get)\n",
    "\n",
    "    r = []\n",
    "    for i in K_max_item_score:\n",
    "        if i in user_pos_test:\n",
    "            r.append(1)\n",
    "        else:\n",
    "            r.append(0)\n",
    "    auc = 0.\n",
    "    return r, auc\n",
    "\n",
    "def get_auc(item_score, user_pos_test):\n",
    "    item_score = sorted(item_score.items(), key=lambda kv: kv[1])\n",
    "    item_score.reverse()\n",
    "    item_sort = [x[0] for x in item_score]\n",
    "    posterior = [x[1] for x in item_score]\n",
    "\n",
    "    r = []\n",
    "    for i in item_sort:\n",
    "        if i in user_pos_test:\n",
    "            r.append(1)\n",
    "        else:\n",
    "            r.append(0)\n",
    "    auc_s = auc(ground_truth=r, prediction=posterior)\n",
    "    return auc_s\n",
    "\n",
    "def ranklist_by_sorted(user_pos_test, test_items, rating, Ks):\n",
    "    item_score = {}\n",
    "    for i in test_items:\n",
    "        item_score[i] = rating[i]\n",
    "\n",
    "    K_max = max(Ks)\n",
    "    K_max_item_score = heapq.nlargest(K_max, item_score, key=item_score.get)\n",
    "\n",
    "    r = []\n",
    "    for i in K_max_item_score:\n",
    "        if i in user_pos_test:\n",
    "            r.append(1)\n",
    "        else:\n",
    "            r.append(0)\n",
    "    auc = get_auc(item_score, user_pos_test)\n",
    "    return r, auc\n",
    "\n",
    "def get_performance(user_pos_test, r, auc, Ks):\n",
    "    precision, recall, ndcg, hit_ratio, mrr = [], [], [], [], []\n",
    "\n",
    "    for K in Ks:\n",
    "        precision.append(precision_at_k(r, K))\n",
    "        recall.append(recall_at_k(r, K, len(user_pos_test)))\n",
    "        ndcg.append(ndcg_at_k(r, K))\n",
    "        hit_ratio.append(hit_at_k(r, K))\n",
    "        mrr.append(mrr_at_k(r, K))\n",
    "\n",
    "    return {'recall': np.array(recall), 'precision': np.array(precision),\n",
    "            'ndcg': np.array(ndcg), 'hit_ratio': np.array(hit_ratio), 'auc': auc, 'mrr': np.array(mrr)}\n",
    "\n",
    "\n",
    "def test_one_user(x):\n",
    "    # user u's ratings for user u\n",
    "    is_val = x[-1]\n",
    "    rating = x[0]\n",
    "    #uid\n",
    "    u = x[1]\n",
    "    #user u's items in the training set\n",
    "    try:\n",
    "        training_items = data_generator.train_items[u]\n",
    "    except Exception:\n",
    "        training_items = []\n",
    "    #user u's items in the test set\n",
    "    if is_val:\n",
    "        user_pos_test = data_generator.val_set[u]\n",
    "    else:\n",
    "        user_pos_test = data_generator.test_set[u]\n",
    "\n",
    "    all_items = set(range(ITEM_NUM))\n",
    "\n",
    "    test_items = list(all_items - set(training_items))\n",
    "\n",
    "    if args.test_flag == 'part':\n",
    "        r, auc = ranklist_by_heapq(user_pos_test, test_items, rating, Ks)\n",
    "    else:\n",
    "        r, auc = ranklist_by_sorted(user_pos_test, test_items, rating, Ks)\n",
    "\n",
    "    return get_performance(user_pos_test, r, auc, Ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee9d053-2b62-4795-97cd-a210c1e975fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_torch(ua_embeddings, ia_embeddings, users_to_test, is_val, drop_flag=False, batch_test_flag=False):\n",
    "    result = {'precision': np.zeros(len(Ks)), 'recall': np.zeros(len(Ks)), 'ndcg': np.zeros(len(Ks)),\n",
    "              'hit_ratio': np.zeros(len(Ks)),'mrr': np.zeros(len(Ks)), 'auc': 0.}\n",
    "    pool = multiprocessing.Pool(cores)\n",
    "\n",
    "    u_batch_size = BATCH_SIZE * 2\n",
    "    i_batch_size = BATCH_SIZE\n",
    "\n",
    "    test_users = users_to_test\n",
    "    n_test_users = len(test_users)\n",
    "    n_user_batchs = n_test_users // u_batch_size + 1\n",
    "    count = 0\n",
    "\n",
    "    for u_batch_id in range(n_user_batchs):\n",
    "        start = u_batch_id * u_batch_size\n",
    "        end = (u_batch_id + 1) * u_batch_size\n",
    "        user_batch = test_users[start: end]\n",
    "        if batch_test_flag:\n",
    "            n_item_batchs = ITEM_NUM // i_batch_size + 1\n",
    "            rate_batch = np.zeros(shape=(len(user_batch), ITEM_NUM))\n",
    "\n",
    "            i_count = 0\n",
    "            for i_batch_id in range(n_item_batchs):\n",
    "                i_start = i_batch_id * i_batch_size\n",
    "                i_end = min((i_batch_id + 1) * i_batch_size, ITEM_NUM)\n",
    "\n",
    "                item_batch = range(i_start, i_end)\n",
    "                u_g_embeddings = ua_embeddings[user_batch]\n",
    "                i_g_embeddings = ia_embeddings[item_batch]\n",
    "                i_rate_batch = torch.matmul(u_g_embeddings, torch.transpose(i_g_embeddings, 0, 1))\n",
    "\n",
    "                rate_batch[:, i_start: i_end] = i_rate_batch\n",
    "                i_count += i_rate_batch.shape[1]\n",
    "\n",
    "            assert i_count == ITEM_NUM\n",
    "\n",
    "        else:\n",
    "            item_batch = range(ITEM_NUM)\n",
    "            u_g_embeddings = ua_embeddings[user_batch]\n",
    "            i_g_embeddings = ia_embeddings[item_batch]\n",
    "            rate_batch = torch.matmul(u_g_embeddings, torch.transpose(i_g_embeddings, 0, 1))\n",
    "\n",
    "        rate_batch = rate_batch.detach().cpu().numpy()\n",
    "        #print(rate_batch.shape)\n",
    "        \n",
    "        user_batch_rating_uid = zip(rate_batch, user_batch, [is_val] * len(user_batch))\n",
    "\n",
    "        batch_result = pool.map(test_one_user, user_batch_rating_uid)\n",
    "        count += len(batch_result)\n",
    "\n",
    "        for re in batch_result:\n",
    "            result['precision'] += re['precision'] / n_test_users\n",
    "            result['recall'] += re['recall'] / n_test_users\n",
    "            result['ndcg'] += re['ndcg'] / n_test_users\n",
    "            result['hit_ratio'] += re['hit_ratio'] / n_test_users\n",
    "            result['auc'] += re['auc'] / n_test_users\n",
    "            result['mrr'] += re['mrr'] / n_test_users\n",
    "\n",
    "    assert count == n_test_users\n",
    "    pool.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17518c1f-6317-4756-b5ee-936dc49e66d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix \n",
    "\n",
    "def build_sim(context):\n",
    "    context_norm = context.div(torch.norm(context, p=2, dim=-1, keepdim=True))\n",
    "    sim = torch.sparse.mm(context_norm, context_norm.transpose(1, 0))\n",
    "    # a, b = context_norm.shape\n",
    "    # b, c = context_norm.transpose(1, 0).shape\n",
    "    # ab = context_norm.unsqueeze(-1)  #.repeat(1,1,c)\n",
    "    # bc = context_norm.transpose(1, 0).unsqueeze(0)  #.repeat(a, 1,1)\n",
    "    # sim = torch.mul(ab, bc).sum(dim=1, keepdim=False)\n",
    "\n",
    "    return sim\n",
    "\n",
    "# def build_knn_normalized_graph(adj, topk, is_sparse, norm_type):\n",
    "#     device = adj.device\n",
    "#     knn_val, knn_ind = torch.topk(adj, topk, dim=-1)\n",
    "#     if is_sparse:\n",
    "#         tuple_list = [[row, int(col)] for row in range(len(knn_ind)) for col in knn_ind[row]]\n",
    "#         row = [i[0] for i in tuple_list]\n",
    "#         col = [i[1] for i in tuple_list]\n",
    "#         i = torch.LongTensor([row, col]).to(device)\n",
    "#         v = knn_val.flatten()\n",
    "#         edge_index, edge_weight = get_sparse_laplacian(i, v, normalization=norm_type, num_nodes=adj.shape[0])\n",
    "#         return torch.sparse_coo_tensor(edge_index, edge_weight, adj.shape)\n",
    "#     else:\n",
    "#         weighted_adjacency_matrix = (torch.zeros_like(adj)).scatter_(-1, knn_ind, knn_val)\n",
    "#         return get_dense_laplacian(weighted_adjacency_matrix, normalization=norm_type)\n",
    "\n",
    "def build_knn_normalized_graph(adj, topk, is_sparse, norm_type):\n",
    "    device = adj.device\n",
    "    knn_val, knn_ind = torch.topk(adj, topk, dim=-1)  #[7050, 10] [7050, 10]\n",
    "    n_item = knn_val.shape[0]\n",
    "    n_data = knn_val.shape[0]*knn_val.shape[1]\n",
    "    data = np.ones(n_data)\n",
    "    if is_sparse:\n",
    "        tuple_list = [[row, int(col)] for row in range(len(knn_ind)) for col in knn_ind[row]]  #[70500]\n",
    "        # data = np.array(knn_val.flatten().cpu())  #args.topk_rate*\n",
    "        row = [i[0] for i in tuple_list]  #[70500]\n",
    "        col = [i[1] for i in tuple_list]  #[70500]\n",
    "        # #-----------------------------------------------------------------------------------------------------\n",
    "        # i = torch.LongTensor([row, col]).to(device)\n",
    "        # v = knn_val.flatten()\n",
    "        # edge_index, edge_weight = get_sparse_laplacian(i, v, normalization=norm_type, num_nodes=adj.shape[0])\n",
    "        # #-----------------------------------------------------------------------------------------------------\n",
    "        ii_graph = csr_matrix((data, (row, col)) ,shape=(n_item, n_item))\n",
    "        # return torch.sparse_coo_tensor(edge_index, edge_weight, adj.shape)\n",
    "        return ii_graph\n",
    "    else:\n",
    "        weighted_adjacency_matrix = (torch.zeros_like(adj)).scatter_(-1, knn_ind, knn_val)\n",
    "        return get_dense_laplacian(weighted_adjacency_matrix, normalization=norm_type)\n",
    "\n",
    "\n",
    "def get_sparse_laplacian(edge_index, edge_weight, num_nodes, normalization='none'):  #[2, 70500], [70500]\n",
    "    from torch_scatter import scatter_add\n",
    "    row, col = edge_index[0], edge_index[1]  #[70500] [70500]\n",
    "    deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)  #[7050]\n",
    "\n",
    "    if normalization == 'sym':\n",
    "        deg_inv_sqrt = deg.pow_(-0.5)\n",
    "        deg_inv_sqrt.masked_fill_(deg_inv_sqrt == float('inf'), 0)\n",
    "        edge_weight = deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
    "    elif normalization == 'rw':\n",
    "        deg_inv = 1.0 / deg\n",
    "        deg_inv.masked_fill_(deg_inv == float('inf'), 0)\n",
    "        edge_weight = deg_inv[row] * edge_weight\n",
    "    return edge_index, edge_weight\n",
    "\n",
    "\n",
    "def get_dense_laplacian(adj, normalization='none'):\n",
    "    if normalization == 'sym':\n",
    "        rowsum = torch.sum(adj, -1)\n",
    "        d_inv_sqrt = torch.pow(rowsum, -0.5)\n",
    "        d_inv_sqrt[torch.isinf(d_inv_sqrt)] = 0.\n",
    "        d_mat_inv_sqrt = torch.diagflat(d_inv_sqrt)\n",
    "        L_norm = torch.mm(torch.mm(d_mat_inv_sqrt, adj), d_mat_inv_sqrt)\n",
    "    elif normalization == 'rw':\n",
    "        rowsum = torch.sum(adj, -1)\n",
    "        d_inv = torch.pow(rowsum, -1)\n",
    "        d_inv[torch.isinf(d_inv)] = 0.\n",
    "        d_mat_inv = torch.diagflat(d_inv)\n",
    "        L_norm = torch.mm(d_mat_inv, adj)\n",
    "    elif normalization == 'none':\n",
    "        L_norm = adj\n",
    "    return L_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2193e0b-8bff-463d-b70e-06e1a4c4ce37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f07db88-aa89-4f37-82ae-594632576a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "import pickle\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "\n",
    "#from utility.parser import parse_args\n",
    "#from utility.norm import build_sim, build_knn_normalized_graph\n",
    "args = parse_args()\n",
    "\n",
    "class MMSSL(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dim, weight_size, dropout_list, image_feats, text_feats):\n",
    "\n",
    "        super().__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.weight_size = weight_size\n",
    "        self.n_ui_layers = len(self.weight_size)\n",
    "        self.weight_size = [self.embedding_dim] + self.weight_size\n",
    "\n",
    "        self.image_trans = nn.Linear(image_feats.shape[1], args.embed_size)\n",
    "        self.text_trans = nn.Linear(text_feats.shape[1], args.embed_size)\n",
    "        nn.init.xavier_uniform_(self.image_trans.weight)\n",
    "        nn.init.xavier_uniform_(self.text_trans.weight)             \n",
    "        self.encoder = nn.ModuleDict() \n",
    "        self.encoder['image_encoder'] = self.image_trans\n",
    "        self.encoder['text_encoder'] = self.text_trans\n",
    "\n",
    "        self.common_trans = nn.Linear(args.embed_size, args.embed_size)\n",
    "        nn.init.xavier_uniform_(self.common_trans.weight)\n",
    "        self.align = nn.ModuleDict() \n",
    "        self.align['common_trans'] = self.common_trans\n",
    "\n",
    "        self.user_id_embedding = nn.Embedding(n_users, self.embedding_dim)\n",
    "        self.item_id_embedding = nn.Embedding(n_items, self.embedding_dim)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.user_id_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.item_id_embedding.weight)\n",
    "        self.image_feats = torch.tensor(image_feats).float().cuda()\n",
    "        self.text_feats = torch.tensor(text_feats).float().cuda()\n",
    "        self.image_embedding = nn.Embedding.from_pretrained(torch.Tensor(image_feats), freeze=False)\n",
    "        self.text_embedding = nn.Embedding.from_pretrained(torch.Tensor(text_feats), freeze=False)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.act = nn.Sigmoid()  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(p=args.drop_rate)\n",
    "        self.batch_norm = nn.BatchNorm1d(args.embed_size)\n",
    "        self.tau = 0.5\n",
    "\n",
    "        initializer = nn.init.xavier_uniform_\n",
    "        self.weight_dict = nn.ParameterDict({\n",
    "            'w_q': nn.Parameter(initializer(torch.empty([args.embed_size, args.embed_size]))),\n",
    "            'w_k': nn.Parameter(initializer(torch.empty([args.embed_size, args.embed_size]))),\n",
    "            'w_v': nn.Parameter(initializer(torch.empty([args.embed_size, args.embed_size]))),\n",
    "            'w_self_attention_item': nn.Parameter(initializer(torch.empty([args.embed_size, args.embed_size]))),\n",
    "            'w_self_attention_user': nn.Parameter(initializer(torch.empty([args.embed_size, args.embed_size]))),\n",
    "            'w_self_attention_cat': nn.Parameter(initializer(torch.empty([args.head_num*args.embed_size, args.embed_size]))),\n",
    "        })\n",
    "        self.embedding_dict = {'user':{}, 'item':{}}\n",
    "\n",
    "    def mm(self, x, y):\n",
    "        if args.sparse:\n",
    "            return torch.sparse.mm(x, y)\n",
    "        else:\n",
    "            return torch.mm(x, y)\n",
    "    def sim(self, z1, z2):\n",
    "        z1 = F.normalize(z1)\n",
    "        z2 = F.normalize(z2)\n",
    "        return torch.mm(z1, z2.t())\n",
    "\n",
    "    def batched_contrastive_loss(self, z1, z2, batch_size=4096):\n",
    "        device = z1.device\n",
    "        num_nodes = z1.size(0)\n",
    "        num_batches = (num_nodes - 1) // batch_size + 1\n",
    "        f = lambda x: torch.exp(x / self.tau)\n",
    "        indices = torch.arange(0, num_nodes).to(device)\n",
    "        losses = []\n",
    "\n",
    "        for i in range(num_batches):\n",
    "            mask = indices[i * batch_size:(i + 1) * batch_size]\n",
    "            refl_sim = f(self.sim(z1[mask], z1))  \n",
    "            between_sim = f(self.sim(z1[mask], z2))  \n",
    "\n",
    "            losses.append(-torch.log(\n",
    "                between_sim[:, i * batch_size:(i + 1) * batch_size].diag()\n",
    "                / (refl_sim.sum(1) + between_sim.sum(1)\n",
    "                   - refl_sim[:, i * batch_size:(i + 1) * batch_size].diag())))\n",
    "                   \n",
    "        loss_vec = torch.cat(losses)\n",
    "        return loss_vec.mean()\n",
    "\n",
    "    def csr_norm(self, csr_mat, mean_flag=False):\n",
    "        rowsum = np.array(csr_mat.sum(1))\n",
    "        rowsum = np.power(rowsum+1e-8, -0.5).flatten()\n",
    "        rowsum[np.isinf(rowsum)] = 0.\n",
    "        rowsum_diag = sp.diags(rowsum)\n",
    "\n",
    "        colsum = np.array(csr_mat.sum(0))\n",
    "        colsum = np.power(colsum+1e-8, -0.5).flatten()\n",
    "        colsum[np.isinf(colsum)] = 0.\n",
    "        colsum_diag = sp.diags(colsum)\n",
    "\n",
    "        if mean_flag == False:\n",
    "            return rowsum_diag*csr_mat*colsum_diag\n",
    "        else:\n",
    "            return rowsum_diag*csr_mat\n",
    "\n",
    "    def matrix_to_tensor(self, cur_matrix):\n",
    "        if type(cur_matrix) != sp.coo_matrix:\n",
    "            cur_matrix = cur_matrix.tocoo()  #\n",
    "        indices = torch.from_numpy(np.vstack((cur_matrix.row, cur_matrix.col)).astype(np.int64))  #\n",
    "        values = torch.from_numpy(cur_matrix.data)  #\n",
    "        shape = torch.Size(cur_matrix.shape)\n",
    "        return torch.sparse_coo_tensor(indices, values, shape, dtype=torch.float32, device='cuda')\n",
    "\n",
    "    def para_dict_to_tenser(self, para_dict):  \n",
    "        \"\"\"\n",
    "        :param para_dict: nn.ParameterDict()\n",
    "        :return: tensor\n",
    "        \"\"\"\n",
    "        tensors = []\n",
    "\n",
    "        for beh in para_dict.keys():\n",
    "            tensors.append(para_dict[beh])\n",
    "        tensors = torch.stack(tensors, dim=0)\n",
    "\n",
    "        return tensors\n",
    "\n",
    "\n",
    "    def multi_head_self_attention(self, trans_w, embedding_t_1, embedding_t):  \n",
    "       \n",
    "        q = self.para_dict_to_tenser(embedding_t)\n",
    "        v = k = self.para_dict_to_tenser(embedding_t_1)\n",
    "        beh, N, d_h = q.shape[0], q.shape[1], args.embed_size/args.head_num\n",
    "\n",
    "        Q = torch.matmul(q, trans_w['w_q'])  \n",
    "        K = torch.matmul(k, trans_w['w_k'])\n",
    "        V = v\n",
    "\n",
    "        Q = Q.reshape(beh, N, args.head_num, int(d_h)).permute(2, 0, 1, 3)  \n",
    "        K = Q.reshape(beh, N, args.head_num, int(d_h)).permute(2, 0, 1, 3)\n",
    "\n",
    "        Q = torch.unsqueeze(Q, 2) \n",
    "        K = torch.unsqueeze(K, 1)  \n",
    "        V = torch.unsqueeze(V, 1)  \n",
    "\n",
    "        att = torch.mul(Q, K) / torch.sqrt(torch.tensor(d_h))  \n",
    "        att = torch.sum(att, dim=-1) \n",
    "        att = torch.unsqueeze(att, dim=-1)  \n",
    "        att = F.softmax(att, dim=2)  \n",
    "\n",
    "        Z = torch.mul(att, V)  \n",
    "        Z = torch.sum(Z, dim=2)  \n",
    "\n",
    "        Z_list = [value for value in Z]\n",
    "        Z = torch.cat(Z_list, -1)\n",
    "        Z = torch.matmul(Z, self.weight_dict['w_self_attention_cat'])\n",
    "\n",
    "        args.model_cat_rate*F.normalize(Z, p=2, dim=2)\n",
    "        return Z, att.detach()\n",
    "\n",
    "    def forward(self, ui_graph, iu_graph, image_ui_graph, image_iu_graph, text_ui_graph, text_iu_graph):\n",
    "\n",
    "        image_feats = image_item_feats = self.dropout(self.image_trans(self.image_feats))\n",
    "        text_feats = text_item_feats = self.dropout(self.text_trans(self.text_feats))\n",
    "\n",
    "        for i in range(args.layers):\n",
    "            image_user_feats = self.mm(ui_graph, image_feats)\n",
    "            image_item_feats = self.mm(iu_graph, image_user_feats)\n",
    "            image_user_id = self.mm(image_ui_graph, self.item_id_embedding.weight)\n",
    "            image_item_id = self.mm(image_iu_graph, self.user_id_embedding.weight)\n",
    "\n",
    "            text_user_feats = self.mm(ui_graph, text_feats)\n",
    "            text_item_feats = self.mm(iu_graph, text_user_feats)\n",
    "            text_user_id = self.mm(text_ui_graph, self.item_id_embedding.weight)\n",
    "            text_item_id = self.mm(text_iu_graph, self.user_id_embedding.weight)\n",
    "\n",
    "        self.embedding_dict['user']['image'] = image_user_id\n",
    "        self.embedding_dict['user']['text'] = text_user_id\n",
    "        self.embedding_dict['item']['image'] = image_item_id\n",
    "        self.embedding_dict['item']['text'] = text_item_id\n",
    "        user_z, _ = self.multi_head_self_attention(self.weight_dict, self.embedding_dict['user'], self.embedding_dict['user'])\n",
    "        item_z, _ = self.multi_head_self_attention(self.weight_dict, self.embedding_dict['item'], self.embedding_dict['item'])\n",
    "        user_emb = user_z.mean(0)\n",
    "        item_emb = item_z.mean(0)\n",
    "        u_g_embeddings = self.user_id_embedding.weight + args.id_cat_rate*F.normalize(user_emb, p=2, dim=1)\n",
    "        i_g_embeddings = self.item_id_embedding.weight + args.id_cat_rate*F.normalize(item_emb, p=2, dim=1)\n",
    "\n",
    "        user_emb_list = [u_g_embeddings]\n",
    "        item_emb_list = [i_g_embeddings]\n",
    "        for i in range(self.n_ui_layers):    \n",
    "            if i == (self.n_ui_layers-1):\n",
    "                u_g_embeddings = self.softmax( torch.mm(ui_graph, i_g_embeddings) ) \n",
    "                i_g_embeddings = self.softmax( torch.mm(iu_graph, u_g_embeddings) )\n",
    "\n",
    "            else:\n",
    "                u_g_embeddings = torch.mm(ui_graph, i_g_embeddings) \n",
    "                i_g_embeddings = torch.mm(iu_graph, u_g_embeddings) \n",
    "\n",
    "            user_emb_list.append(u_g_embeddings)\n",
    "            item_emb_list.append(i_g_embeddings)\n",
    "\n",
    "        u_g_embeddings = torch.mean(torch.stack(user_emb_list), dim=0)\n",
    "        i_g_embeddings = torch.mean(torch.stack(item_emb_list), dim=0)\n",
    "\n",
    "\n",
    "        u_g_embeddings = u_g_embeddings + args.model_cat_rate*F.normalize(image_user_feats, p=2, dim=1) + args.model_cat_rate*F.normalize(text_user_feats, p=2, dim=1)\n",
    "        i_g_embeddings = i_g_embeddings + args.model_cat_rate*F.normalize(image_item_feats, p=2, dim=1) + args.model_cat_rate*F.normalize(text_item_feats, p=2, dim=1)\n",
    "\n",
    "        return u_g_embeddings, i_g_embeddings, image_item_feats, text_item_feats, image_user_feats, text_user_feats, u_g_embeddings, i_g_embeddings, image_user_id, text_user_id, image_item_id, text_item_id\n",
    "\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, int(dim/4)),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.BatchNorm1d(int(dim/4)),\n",
    "    \t\tnn.Dropout(args.G_drop1),\n",
    "\n",
    "            nn.Linear(int(dim/4), int(dim/8)),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.BatchNorm1d(int(dim/8)),\n",
    "    \t\tnn.Dropout(args.G_drop2),\n",
    "\n",
    "            nn.Linear(int(dim/8), 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = 100*self.net(x.float())  \n",
    "        return output.view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b90e82f-6aa6-47dc-8174-4b5fd95964fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "#import  visdom\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.sparse as sparse\n",
    "from torch import autograd\n",
    "\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d28be5-af59-455a-a236-a9d7740a9367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as tm\n",
    "\n",
    "\n",
    "#from utility.parser import parse_args\n",
    "#from Models import MMSSL, Discriminator\n",
    "#from utility.batch_test import *\n",
    "#from utility.logging import Logger\n",
    "#from utility.norm import build_sim, build_knn_normalized_graph\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, data_config):\n",
    "       \n",
    "        self.task_name = \"%s_%s_%s\" % (datetime.now().strftime('%Y-%m-%d %H:%M:%S'), args.dataset, args.cf_model,)\n",
    "        self.logger = Logger(filename=self.task_name, is_debug=args.debug)\n",
    "        self.logger.logging(\"PID: %d\" % os.getpid())\n",
    "        self.logger.logging(str(args))\n",
    "\n",
    "        self.mess_dropout = eval(args.mess_dropout)\n",
    "        self.lr = args.lr\n",
    "        self.emb_dim = args.embed_size\n",
    "        self.batch_size = args.batch_size\n",
    "        self.weight_size = eval(args.weight_size)\n",
    "        self.n_layers = len(self.weight_size)\n",
    "        self.regs = eval(args.regs)\n",
    "        self.decay = self.regs[0]\n",
    " \n",
    "        if args.shuffle=='all':\n",
    "            self.image_feats = np.load('./{}/clip_shuffled_{}_image_feats.npy'.format(args.dataset,args.p))\n",
    "            self.text_feats = np.load('./{}/clip_shuffled_{}_text_feats.npy'.format(args.dataset,args.p))\n",
    "            print('./{}/clip_shuffled_{}_image_feats.npy'.format(args.dataset,args.p))\n",
    "            print('./{}/clip_shuffled_{}_text_feats.npy'.format(args.dataset,args.p))\n",
    "        elif args.shuffle=='text':\n",
    "            self.image_feats = np.load('./{}/clip_shuffled_0_image_feats.npy'.format(args.dataset))\n",
    "            self.text_feats = np.load('./{}/clip_shuffled_{}_text_feats.npy'.format(args.dataset,args.p))\n",
    "            print('./{}/clip_shuffled_0_image_feats.npy'.format(args.dataset))\n",
    "            print('./{}/clip_shuffled_{}_text_feats.npy'.format(args.dataset,args.p))\n",
    "        elif args.shuffle=='image':\n",
    "            self.image_feats = np.load('./{}/clip_shuffled_{}_image_feats.npy'.format(args.dataset,args.p))\n",
    "            self.text_feats = np.load('./{}/clip_shuffled_0_text_feats.npy'.format(args.dataset))\n",
    "            print('./{}/clip_shuffled_{}_image_feats.npy'.format(args.dataset,args.p))\n",
    "            print('./{}/clip_shuffled_0_text_feats.npy'.format(args.dataset))\n",
    "        else:\n",
    "            self.image_feats = np.load('./{}/clip_shuffled_0_image_feats.npy'.format(args.dataset))\n",
    "            self.text_feats = np.load('./{}/clip_shuffled_0_text_feats.npy'.format(args.dataset))\n",
    "            print('./{}/clip_shuffled_0_image_feats.npy'.format(args.dataset))\n",
    "            print('./{}/clip_shuffled_0_text_feats.npy'.format(args.dataset))\n",
    "        \n",
    "        self.image_feat_dim = self.image_feats.shape[-1]\n",
    "        self.text_feat_dim = self.text_feats.shape[-1]\n",
    "        self.ui_graph = self.ui_graph_raw = pickle.load(open(args.data_path + args.dataset + '/%d-core' % args.core + '/train_mat','rb'))\n",
    "        self.image_ui_graph_tmp = self.text_ui_graph_tmp = torch.tensor(self.ui_graph_raw.todense()).cuda()\n",
    "        self.image_iu_graph_tmp = self.text_iu_graph_tmp = torch.tensor(self.ui_graph_raw.T.todense()).cuda()\n",
    "        self.image_ui_index = {'x':[], 'y':[]}\n",
    "        self.text_ui_index = {'x':[], 'y':[]}\n",
    "        self.n_users = self.ui_graph.shape[0]\n",
    "        self.n_items = self.ui_graph.shape[1]        \n",
    "        self.iu_graph = self.ui_graph.T\n",
    "        self.ui_graph = self.matrix_to_tensor(self.csr_norm(self.ui_graph, mean_flag=True))\n",
    "        self.iu_graph = self.matrix_to_tensor(self.csr_norm(self.iu_graph, mean_flag=True))\n",
    "        self.image_ui_graph = self.text_ui_graph = self.ui_graph\n",
    "        self.image_iu_graph = self.text_iu_graph = self.iu_graph\n",
    "        self.model = MMSSL(self.n_users, self.n_items, self.emb_dim, self.weight_size, self.mess_dropout, self.image_feats, self.text_feats)      \n",
    "        self.model = self.model.cuda()\n",
    "        self.D = Discriminator(self.n_items).cuda()\n",
    "        self.D.apply(self.weights_init)\n",
    "        self.optim_D = optim.Adam(self.D.parameters(), lr=args.D_lr, betas=(0.5, 0.9))  \n",
    "\n",
    "        self.optimizer_D = optim.AdamW(\n",
    "        [\n",
    "            {'params':self.model.parameters()},      \n",
    "        ]\n",
    "            , lr=self.lr)  \n",
    "        self.scheduler_D = self.set_lr_scheduler()\n",
    "\n",
    "\n",
    "    def set_lr_scheduler(self):\n",
    "        fac = lambda epoch: 0.96 ** (epoch / 50)\n",
    "        scheduler_D = optim.lr_scheduler.LambdaLR(self.optimizer_D, lr_lambda=fac)\n",
    "        return scheduler_D  \n",
    "\n",
    "    def csr_norm(self, csr_mat, mean_flag=False):\n",
    "        rowsum = np.array(csr_mat.sum(1))\n",
    "        rowsum = np.power(rowsum+1e-8, -0.5).flatten()\n",
    "        rowsum[np.isinf(rowsum)] = 0.\n",
    "        rowsum_diag = sp.diags(rowsum)\n",
    "\n",
    "        colsum = np.array(csr_mat.sum(0))\n",
    "        colsum = np.power(colsum+1e-8, -0.5).flatten()\n",
    "        colsum[np.isinf(colsum)] = 0.\n",
    "        colsum_diag = sp.diags(colsum)\n",
    "\n",
    "        if mean_flag == False:\n",
    "            return rowsum_diag*csr_mat*colsum_diag\n",
    "        else:\n",
    "            return rowsum_diag*csr_mat\n",
    "\n",
    "    def matrix_to_tensor(self, cur_matrix):\n",
    "        if type(cur_matrix) != sp.coo_matrix:\n",
    "            cur_matrix = cur_matrix.tocoo()  #\n",
    "        indices = torch.from_numpy(np.vstack((cur_matrix.row, cur_matrix.col)).astype(np.int64))  #\n",
    "        values = torch.from_numpy(cur_matrix.data)  #\n",
    "        shape = torch.Size(cur_matrix.shape)\n",
    "\n",
    "        return torch.sparse.FloatTensor(indices, values, shape).to(torch.float32).cuda()  #\n",
    "\n",
    "    def innerProduct(self, u_pos, i_pos, u_neg, j_neg):  \n",
    "        pred_i = torch.sum(torch.mul(u_pos,i_pos), dim=-1) \n",
    "        pred_j = torch.sum(torch.mul(u_neg,j_neg), dim=-1)  \n",
    "        return pred_i, pred_j\n",
    "\n",
    "    def sampleTrainBatch_dgl(self, batIds, pos_id=None, g=None, g_neg=None, sample_num=None, sample_num_neg=None):\n",
    "\n",
    "        sub_g = dgl.sampling.sample_neighbors(g.cpu(), {'user':batIds}, sample_num, edge_dir='out', replace=True)\n",
    "        row, col = sub_g.edges()\n",
    "        row = row.reshape(len(batIds), sample_num)\n",
    "        col = col.reshape(len(batIds), sample_num)\n",
    "\n",
    "        if g_neg==None:\n",
    "            return row, col\n",
    "        else: \n",
    "            sub_g_neg = dgl.sampling.sample_neighbors(g_neg, {'user':batIds}, sample_num_neg, edge_dir='out', replace=True)\n",
    "            row_neg, col_neg = sub_g_neg.edges()\n",
    "            row_neg = row_neg.reshape(len(batIds), sample_num_neg)\n",
    "            col_neg = col_neg.reshape(len(batIds), sample_num_neg)\n",
    "            return row, col, col_neg \n",
    "\n",
    "    def weights_init(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "    def gradient_penalty(self, D, xr, xf):\n",
    "\n",
    "        LAMBDA = 0.3\n",
    "\n",
    "        xf = xf.detach()\n",
    "        xr = xr.detach()\n",
    "\n",
    "        alpha = torch.rand(args.batch_size*2, 1).cuda()\n",
    "        alpha = alpha.expand_as(xr)\n",
    "\n",
    "        interpolates = alpha * xr + ((1 - alpha) * xf)\n",
    "        interpolates.requires_grad_()\n",
    "\n",
    "        disc_interpolates = D(interpolates)\n",
    "\n",
    "        gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                                grad_outputs=torch.ones_like(disc_interpolates),\n",
    "                                create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "        gp = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
    "\n",
    "        return gp\n",
    "\n",
    "    def weighted_sum(self, anchor, nei, co):  \n",
    "\n",
    "        ac = torch.multiply(anchor, co).sum(-1).sum(-1)  \n",
    "        nc = torch.multiply(nei, co).sum(-1).sum(-1)  \n",
    "\n",
    "        an = (anchor.permute(1, 0, 2)[0])\n",
    "        ne = (nei.permute(1, 0, 2)[0])\n",
    "\n",
    "        an_w = an*(ac.unsqueeze(-1).repeat(1, args.embed_size))\n",
    "        ne_w = ne*(nc.unsqueeze(-1).repeat(1, args.embed_size))                                     \n",
    "  \n",
    "        res = (args.anchor_rate*an_w + (1-args.anchor_rate)*ne_w).reshape(-1, args.sample_num_ii, args.embed_size).sum(1)\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "    def sample_topk(self, u_sim, users, emb_type=None):\n",
    "        topk_p, topk_id = torch.topk(u_sim, args.ad_topk*10, dim=-1)  \n",
    "        topk_data = topk_p.reshape(-1).cpu()\n",
    "        topk_col = topk_id.reshape(-1).cpu().int()\n",
    "        topk_row = torch.tensor(np.array(users)).unsqueeze(1).repeat(1, args.ad_topk*args.ad_topk_multi_num).reshape(-1).int()  #\n",
    "        topk_csr = csr_matrix((topk_data.detach().numpy(), (topk_row.detach().numpy(), topk_col.detach().numpy())), shape=(self.n_users, self.n_items))\n",
    "        topk_g = dgl.heterograph({('user','ui','item'):topk_csr.nonzero()})\n",
    "        _, topk_id = self.sampleTrainBatch_dgl(users, g=topk_g, sample_num=args.ad_topk, pos_id=None, g_neg=None, sample_num_neg=None)\n",
    "        self.gene_fake[emb_type] = topk_id\n",
    "\n",
    "        topk_id_u = torch.arange(len(users)).unsqueeze(1).repeat(1, args.ad_topk)\n",
    "        topk_p = u_sim[topk_id_u, topk_id]\n",
    "        return topk_p, topk_id\n",
    "\n",
    "    def ssl_loss_calculation(self, ssl_image_logit, ssl_text_logit, ssl_common_logit):\n",
    "        ssl_label_1_s2 = torch.ones(1, self.n_items).cuda()\n",
    "        ssl_label_0_s2 = torch.zeros(1, self.n_items).cuda()\n",
    "        ssl_label_s2 = torch.cat((ssl_label_1_s2, ssl_label_0_s2), 1)\n",
    "        ssl_image_s2 = self.bce(ssl_image_logit, ssl_label_s2)\n",
    "        ssl_text_s2 = self.bce(ssl_text_logit, ssl_label_s2)\n",
    "        ssl_loss_s2 = ssl_image_s2 + ssl_text_s2\n",
    "\n",
    "        ssl_label_1_c2 = torch.ones(1, self.n_items*2).cuda()\n",
    "        ssl_label_0_c2 = torch.zeros(1, self.n_items*2).cuda()\n",
    "        ssl_label_c2 = torch.cat((ssl_label_1_c2, ssl_label_0_c2), 1)\n",
    "        ssl_result_c2 = self.bce(ssl_common_logit, ssl_label_c2)  \n",
    "        ssl_loss_c2 = ssl_result_c2\n",
    "\n",
    "        ssl_loss2 = args.ssl_s_rate*ssl_loss_s2 + args.ssl_c_rate*ssl_loss_c2 \n",
    "        return ssl_loss2\n",
    "\n",
    "\n",
    "    def sim(self, z1, z2):\n",
    "        z1 = F.normalize(z1)  \n",
    "        z2 = F.normalize(z2)\n",
    "        # z1 = z1/((z1**2).sum(-1) + 1e-8)\n",
    "        # z2 = z2/((z2**2).sum(-1) + 1e-8)\n",
    "        return torch.mm(z1, z2.t())\n",
    "\n",
    "    def batched_contrastive_loss(self, z1, z2, batch_size=1024):\n",
    "\n",
    "        device = z1.device\n",
    "        num_nodes = z1.size(0)\n",
    "        num_batches = (num_nodes - 1) // batch_size + 1\n",
    "        f = lambda x: torch.exp(x / args.tau)   #       \n",
    "\n",
    "        indices = torch.arange(0, num_nodes).to(device)\n",
    "        losses = []\n",
    "\n",
    "        for i in range(num_batches):\n",
    "            tmp_i = indices[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "            tmp_refl_sim_list = []\n",
    "            tmp_between_sim_list = []\n",
    "            for j in range(num_batches):\n",
    "                tmp_j = indices[j * batch_size:(j + 1) * batch_size]\n",
    "                tmp_refl_sim = f(self.sim(z1[tmp_i], z1[tmp_j]))  \n",
    "                tmp_between_sim = f(self.sim(z1[tmp_i], z2[tmp_j]))  \n",
    "\n",
    "                tmp_refl_sim_list.append(tmp_refl_sim)\n",
    "                tmp_between_sim_list.append(tmp_between_sim)\n",
    "\n",
    "            refl_sim = torch.cat(tmp_refl_sim_list, dim=-1)\n",
    "            between_sim = torch.cat(tmp_between_sim_list, dim=-1)\n",
    "\n",
    "            losses.append(-torch.log(between_sim[:, i * batch_size:(i + 1) * batch_size].diag()/ (refl_sim.sum(1) + between_sim.sum(1) - refl_sim[:, i * batch_size:(i + 1) * batch_size].diag())+1e-8))\n",
    "\n",
    "            del refl_sim, between_sim, tmp_refl_sim_list, tmp_between_sim_list\n",
    "                   \n",
    "        loss_vec = torch.cat(losses)\n",
    "        return loss_vec.mean()\n",
    "\n",
    "\n",
    "    def feat_reg_loss_calculation(self, g_item_image, g_item_text, g_user_image, g_user_text):\n",
    "        feat_reg = 1./2*(g_item_image**2).sum() + 1./2*(g_item_text**2).sum() \\\n",
    "            + 1./2*(g_user_image**2).sum() + 1./2*(g_user_text**2).sum()        \n",
    "        feat_reg = feat_reg / self.n_items\n",
    "        feat_emb_loss = args.feat_reg_decay * feat_reg\n",
    "        return feat_emb_loss\n",
    "\n",
    "\n",
    "    def fake_gene_loss_calculation(self, u_emb, i_emb, emb_type=None):\n",
    "        if self.gene_u!=None:\n",
    "            gene_real_loss = (-F.logsigmoid((u_emb[self.gene_u]*i_emb[self.gene_real]).sum(-1)+1e-8)).mean()\n",
    "            gene_fake_loss = (1-(-F.logsigmoid((u_emb[self.gene_u]*i_emb[self.gene_fake[emb_type]]).sum(-1)+1e-8))).mean()\n",
    "\n",
    "            gene_loss = gene_real_loss + gene_fake_loss\n",
    "        else:\n",
    "            gene_loss = 0\n",
    "\n",
    "        return gene_loss\n",
    "\n",
    "    def reward_loss_calculation(self, users, re_u, re_i, topk_id, topk_p):\n",
    "        self.gene_u = torch.tensor(np.array(users)).unsqueeze(1).repeat(1, args.ad_topk)\n",
    "        reward_u = re_u[self.gene_u]\n",
    "        reward_i = re_i[topk_id]\n",
    "        reward_value = (reward_u*reward_i).sum(-1)\n",
    "\n",
    "        reward_loss = -(((topk_p*reward_value).sum(-1)).mean()+1e-8).log()\n",
    "        \n",
    "        return reward_loss\n",
    "\n",
    "\n",
    "\n",
    "    def u_sim_calculation(self, users, user_final, item_final):\n",
    "        topk_u = user_final[users]\n",
    "        u_ui = torch.tensor(self.ui_graph_raw[users].todense()).cuda()\n",
    "\n",
    "        num_batches = (self.n_items - 1) // args.batch_size + 1\n",
    "        indices = torch.arange(0, self.n_items).cuda()\n",
    "        u_sim_list = []\n",
    "\n",
    "        for i_b in range(num_batches):\n",
    "            index = indices[i_b * args.batch_size:(i_b + 1) * args.batch_size]\n",
    "            sim = torch.mm(topk_u, item_final[index].T)\n",
    "            sim_gt = torch.multiply(sim, (1-u_ui[:, index]))\n",
    "            u_sim_list.append(sim_gt)\n",
    "                \n",
    "        u_sim = F.normalize(torch.cat(u_sim_list, dim=-1), p=2, dim=1)   \n",
    "        return u_sim\n",
    "\n",
    "\n",
    "    def test(self, users_to_test, is_val):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            ua_embeddings, ia_embeddings, *rest = self.model(self.ui_graph, self.iu_graph, self.image_ui_graph, self.image_iu_graph, self.text_ui_graph, self.text_iu_graph)\n",
    "        result = test_torch(ua_embeddings, ia_embeddings, users_to_test, is_val)\n",
    "        #result = my_test_torch(ua_embeddings, ia_embeddings, users_to_test, is_val)\n",
    "        return result\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        now_time = datetime.now()\n",
    "        run_time = datetime.strftime(now_time,'%Y_%m_%d__%H_%M_%S')\n",
    "\n",
    "        training_time_list = []\n",
    "        loss_loger, pre_loger, rec_loger, ndcg_loger, hit_loger,mrr_loger = [], [], [], [], [], []\n",
    "        line_var_loss, line_g_loss, line_d_loss, line_cl_loss, line_var_recall, line_var_precision, line_var_ndcg = [], [], [], [], [], [], []\n",
    "        stopping_step = 0\n",
    "        should_stop = False\n",
    "        cur_best_pre_0 = 0. \n",
    "        # tb_writer = SummaryWriter(log_dir=\"/home/ww/Code/work5/MICRO2Ours/tensorboard/\")\n",
    "        # tensorboard_cnt = 0\n",
    "\n",
    "        n_batch = data_generator.n_train // args.batch_size + 1\n",
    "        best_recall = 0\n",
    "        for epoch in range(args.epoch):\n",
    "            t1 = time()\n",
    "            loss, mf_loss, emb_loss, reg_loss = 0., 0., 0., 0.\n",
    "            contrastive_loss = 0.\n",
    "            n_batch = data_generator.n_train // args.batch_size + 1\n",
    "            sample_time = 0.\n",
    "            self.gene_u, self.gene_real, self.gene_fake = None, None, {}\n",
    "            self.topk_p_dict, self.topk_id_dict = {}, {}\n",
    "\n",
    "            for idx in tqdm(range(n_batch)):\n",
    "                self.model.train()\n",
    "                sample_t1 = time()\n",
    "                users, pos_items, neg_items = data_generator.sample()\n",
    "                sample_time += time() - sample_t1       \n",
    "\n",
    "                with torch.no_grad():\n",
    "                    ua_embeddings, ia_embeddings, image_item_embeds, text_item_embeds, image_user_embeds, text_user_embeds \\\n",
    "                                    , _, _, _, _, _, _ \\\n",
    "                            = self.model(self.ui_graph, self.iu_graph, self.image_ui_graph, self.image_iu_graph, self.text_ui_graph, self.text_iu_graph)\n",
    "                ui_u_sim_detach = self.u_sim_calculation(users, ua_embeddings, ia_embeddings).detach()\n",
    "                image_u_sim_detach = self.u_sim_calculation(users, image_user_embeds, image_item_embeds).detach()\n",
    "                text_u_sim_detach = self.u_sim_calculation(users, text_user_embeds, text_item_embeds).detach()\n",
    "                inputf = torch.cat((image_u_sim_detach, text_u_sim_detach), dim=0)\n",
    "                predf = (self.D(inputf))\n",
    "                lossf = (predf.mean())\n",
    "                u_ui = torch.tensor(self.ui_graph_raw[users].todense()).cuda()\n",
    "                u_ui = F.softmax(u_ui - args.log_log_scale*torch.log(-torch.log(torch.empty((u_ui.shape[0], u_ui.shape[1]), dtype=torch.float32).uniform_(0,1).cuda()+1e-8)+1e-8)/args.real_data_tau, dim=1) #0.002  \n",
    "                u_ui += ui_u_sim_detach*args.ui_pre_scale                  \n",
    "                u_ui = F.normalize(u_ui, dim=1)  \n",
    "                inputr = torch.cat((u_ui, u_ui), dim=0)\n",
    "                predr = (self.D(inputr))\n",
    "                lossr = - (predr.mean())\n",
    "                gp = self.gradient_penalty(self.D, inputr, inputf.detach())\n",
    "                loss_D = lossr + lossf + args.gp_rate*gp \n",
    "                self.optim_D.zero_grad()\n",
    "                loss_D.backward()\n",
    "                self.optim_D.step()\n",
    "                line_d_loss.append(loss_D.detach().data)\n",
    "\n",
    "                G_ua_embeddings, G_ia_embeddings, G_image_item_embeds, G_text_item_embeds, G_image_user_embeds, G_text_user_embeds \\\n",
    "                                , G_user_emb, _, G_image_user_id, G_text_user_id, _, _ \\\n",
    "                        = self.model(self.ui_graph, self.iu_graph, self.image_ui_graph, self.image_iu_graph, self.text_ui_graph, self.text_iu_graph)\n",
    "\n",
    "\n",
    "                G_u_g_embeddings = G_ua_embeddings[users]\n",
    "                G_pos_i_g_embeddings = G_ia_embeddings[pos_items]\n",
    "                G_neg_i_g_embeddings = G_ia_embeddings[neg_items]\n",
    "                G_batch_mf_loss, G_batch_emb_loss, G_batch_reg_loss = self.bpr_loss(G_u_g_embeddings, G_pos_i_g_embeddings, G_neg_i_g_embeddings)\n",
    "                G_image_u_sim = self.u_sim_calculation(users, G_image_user_embeds, G_image_item_embeds)\n",
    "                G_text_u_sim = self.u_sim_calculation(users, G_text_user_embeds, G_text_item_embeds)\n",
    "                G_image_u_sim_detach = G_image_u_sim.detach() \n",
    "                G_text_u_sim_detach = G_text_u_sim.detach()\n",
    "\n",
    "\n",
    "                if idx%args.T==0 and idx!=0:\n",
    "                    self.image_ui_graph_tmp = csr_matrix((torch.ones(len(self.image_ui_index['x'])),(self.image_ui_index['x'], self.image_ui_index['y'])), shape=(self.n_users, self.n_items))\n",
    "                    self.text_ui_graph_tmp = csr_matrix((torch.ones(len(self.text_ui_index['x'])),(self.text_ui_index['x'], self.text_ui_index['y'])), shape=(self.n_users, self.n_items))\n",
    "                    self.image_iu_graph_tmp = self.image_ui_graph_tmp.T\n",
    "                    self.text_iu_graph_tmp = self.text_ui_graph_tmp.T\n",
    "                    self.image_ui_graph = self.sparse_mx_to_torch_sparse_tensor( \\\n",
    "                        self.csr_norm(self.image_ui_graph_tmp, mean_flag=True)\n",
    "                        ).cuda() \n",
    "                    self.text_ui_graph = self.sparse_mx_to_torch_sparse_tensor(\n",
    "                        self.csr_norm(self.text_ui_graph_tmp, mean_flag=True)\n",
    "                        ).cuda()\n",
    "                    self.image_iu_graph = self.sparse_mx_to_torch_sparse_tensor(\n",
    "                        self.csr_norm(self.image_iu_graph_tmp, mean_flag=True)\n",
    "                        ).cuda()\n",
    "                    self.text_iu_graph = self.sparse_mx_to_torch_sparse_tensor(\n",
    "                        self.csr_norm(self.text_iu_graph_tmp, mean_flag=True)\n",
    "                        ).cuda()\n",
    "\n",
    "                    self.image_ui_index = {'x':[], 'y':[]}\n",
    "                    self.text_ui_index = {'x':[], 'y':[]}\n",
    "\n",
    "                else:\n",
    "                    _, image_ui_id = torch.topk(G_image_u_sim_detach, int(self.n_items*args.m_topk_rate), dim=-1)\n",
    "                    self.image_ui_index['x'] += np.array(torch.tensor(users).repeat(1, int(self.n_items*args.m_topk_rate)).view(-1)).tolist()\n",
    "                    self.image_ui_index['y'] += np.array(image_ui_id.cpu().view(-1)).tolist()\n",
    "                    _, text_ui_id = torch.topk(G_text_u_sim_detach, int(self.n_items*args.m_topk_rate), dim=-1)\n",
    "                    self.text_ui_index['x'] += np.array(torch.tensor(users).repeat(1, int(self.n_items*args.m_topk_rate)).view(-1)).tolist()\n",
    "                    self.text_ui_index['y'] += np.array(text_ui_id.cpu().view(-1)).tolist()\n",
    "\n",
    "\n",
    "                feat_emb_loss = self.feat_reg_loss_calculation(G_image_item_embeds, G_text_item_embeds, G_image_user_embeds, G_text_user_embeds)\n",
    "\n",
    "                batch_contrastive_loss = 0\n",
    "                batch_contrastive_loss1 = self.batched_contrastive_loss(G_image_user_id[users],G_user_emb[users])\n",
    "                batch_contrastive_loss2 = self.batched_contrastive_loss(G_text_user_id[users],G_user_emb[users])\n",
    "  \n",
    "                batch_contrastive_loss = batch_contrastive_loss1 + batch_contrastive_loss2 \n",
    "    \n",
    "                G_inputf = torch.cat((G_image_u_sim, G_text_u_sim), dim=0)\n",
    "                G_predf = (self.D(G_inputf))\n",
    "\n",
    "                G_lossf = -(G_predf.mean())\n",
    "                batch_loss = G_batch_mf_loss + G_batch_emb_loss + G_batch_reg_loss + feat_emb_loss + args.cl_rate*batch_contrastive_loss + args.G_rate*G_lossf  #feat_emb_loss\n",
    "\n",
    "                line_var_loss.append(batch_loss.detach().data)\n",
    "                line_g_loss.append(G_lossf.detach().data)\n",
    "                line_cl_loss.append(batch_contrastive_loss.detach().data)\n",
    "                             \n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
    "                self.optimizer_D.zero_grad()  \n",
    "                batch_loss.backward(retain_graph=False)\n",
    "                self.optimizer_D.step()\n",
    "\n",
    "                loss += float(batch_loss)\n",
    "                mf_loss += float(G_batch_mf_loss)\n",
    "                emb_loss += float(G_batch_emb_loss)\n",
    "                reg_loss += float(G_batch_reg_loss)\n",
    "    \n",
    "    \n",
    "            del ua_embeddings, ia_embeddings, G_ua_embeddings, G_ia_embeddings, G_u_g_embeddings, G_neg_i_g_embeddings, G_pos_i_g_embeddings\n",
    "\n",
    "\n",
    "            if math.isnan(loss) == True:\n",
    "                self.logger.logging('ERROR: loss is nan.')\n",
    "                sys.exit()\n",
    "\n",
    "            if (epoch + 1) % args.verbose != 0:\n",
    "                perf_str = 'Epoch %d [%.1fs]: train==[%.5f=%.5f + %.5f + %.5f  + %.5f]' % (\n",
    "                    epoch, time() - t1, loss, mf_loss, emb_loss, reg_loss, contrastive_loss)\n",
    "                training_time_list.append(time() - t1)\n",
    "                self.logger.logging(perf_str)\n",
    "\n",
    "            t2 = time()\n",
    "            users_to_test = list(data_generator.test_set.keys())\n",
    "            users_to_val = list(data_generator.val_set.keys())\n",
    "            ret = self.test(users_to_val, is_val=True)  \n",
    "            training_time_list.append(t2 - t1)\n",
    "\n",
    "            t3 = time()\n",
    "\n",
    "            loss_loger.append(loss)\n",
    "            rec_loger.append(ret['recall'].data)\n",
    "            pre_loger.append(ret['precision'].data)\n",
    "            ndcg_loger.append(ret['ndcg'].data)\n",
    "            hit_loger.append(ret['hit_ratio'].data)\n",
    "            mrr_loger.append(ret['mrr'])\n",
    "\n",
    "            line_var_recall.append(ret['recall'][1])\n",
    "            line_var_precision.append(ret['precision'][1])\n",
    "            line_var_ndcg.append(ret['ndcg'][1])\n",
    "\n",
    "            tags = [\"recall\", \"precision\", \"ndcg\"]\n",
    "            # tb_writer.add_scalar(tags[0], ret['recall'][1], epoch)\n",
    "            # tb_writer.add_scalar(tags[1], ret['precision'][1], epoch)\n",
    "            # tb_writer.add_scalar(tags[2], ret['ndcg'][1], epoch)\n",
    "\n",
    "\n",
    "            if args.verbose > 0:\n",
    "                perf_str = 'Epoch %d [%.1fs + %.1fs]: train==[%.5f=%.5f + %.5f + %.5f], recall=[%.5f, %.5f, %.5f, %.5f], ' \\\n",
    "                           'precision=[%.5f, %.5f, %.5f, %.5f], hit=[%.5f, %.5f, %.5f, %.5f], ndcg=[%.5f, %.5f, %.5f, %.5f], mrr=[%.5f, %.5f]' % \\\n",
    "                           (epoch, t2 - t1, t3 - t2, loss, mf_loss, emb_loss, reg_loss, ret['recall'][0], ret['recall'][1], ret['recall'][2],\n",
    "                            ret['recall'][-1],\n",
    "                            ret['precision'][0], ret['precision'][1], ret['precision'][2], ret['precision'][-1], ret['hit_ratio'][0], ret['hit_ratio'][1], ret['hit_ratio'][2], ret['hit_ratio'][-1],\n",
    "                            ret['ndcg'][0], ret['ndcg'][1], ret['ndcg'][2], ret['ndcg'][-1],ret['mrr'][0], ret['mrr'][1])\n",
    "                self.logger.logging(perf_str)\n",
    "\n",
    "            if ret['recall'][1] > best_recall:\n",
    "                best_recall = ret['recall'][1]\n",
    "                test_ret = self.test(users_to_test, is_val=False)\n",
    "                self.logger.logging(\"Test_Recall@%d: %.5f,  precision=[%.5f], ndcg=[%.5f]\" % (eval(args.Ks)[1], test_ret['recall'][1], test_ret['precision'][1], test_ret['ndcg'][1]))\n",
    "                stopping_step = 0\n",
    "            elif stopping_step < args.early_stopping_patience:\n",
    "                stopping_step += 1\n",
    "                self.logger.logging('#####Early stopping steps: %d #####' % stopping_step)\n",
    "            else:\n",
    "                self.logger.logging('#####Early stop! #####')\n",
    "                break\n",
    "        self.logger.logging(str(test_ret))\n",
    "        print(test_ret)\n",
    "        print(args.dataset,args.shuffle,args.p,tm.strftime(\"%a %b %d %H:%M:%S %Y\", tm.localtime()),test_ret, file=open('test_mmssl_ret.txt','a'))\n",
    "\n",
    "        return best_recall, run_time\n",
    "\n",
    "    def val_loss(self):\n",
    "\n",
    "        loss_loger, pre_loger, rec_loger, ndcg_loger, hit_loger = [], [], [], [], []\n",
    "        n_batch = data_generator.n_val // args.batch_size + 1\n",
    "        best_recall = 0\n",
    "        loss, mf_loss, emb_loss, reg_loss = 0., 0., 0., 0.\n",
    "        contrastive_loss = 0.\n",
    "        n_batch = data_generator.n_train // args.batch_size + 1\n",
    "        self.gene_u, self.gene_real, self.gene_fake = None, None, {}\n",
    "        self.topk_p_dict, self.topk_id_dict = {}, {}\n",
    "\n",
    "        for idx in tqdm(range(n_batch)):\n",
    "            users, pos_items, neg_items = data_generator.sample() \n",
    "\n",
    "            with torch.no_grad():\n",
    "                ua_embeddings, ia_embeddings, image_item_embeds, text_item_embeds, image_user_embeds, text_user_embeds \\\n",
    "                                , _, _, _, _, _, _ \\\n",
    "                        = self.model(self.ui_graph, self.iu_graph, self.image_ui_graph, self.image_iu_graph, self.text_ui_graph, self.text_iu_graph)\n",
    "            ui_u_sim_detach = self.u_sim_calculation(users, ua_embeddings, ia_embeddings).detach()\n",
    "            image_u_sim_detach = self.u_sim_calculation(users, image_user_embeds, image_item_embeds).detach()\n",
    "            text_u_sim_detach = self.u_sim_calculation(users, text_user_embeds, text_item_embeds).detach()\n",
    "            inputf = torch.cat((image_u_sim_detach, text_u_sim_detach), dim=0)\n",
    "            predf = (self.D(inputf))\n",
    "            lossf = (predf.mean())\n",
    "            u_ui = torch.tensor(self.ui_graph_raw[users].todense()).cuda()\n",
    "            u_ui = F.softmax(u_ui - args.log_log_scale*torch.log(-torch.log(torch.empty((u_ui.shape[0], u_ui.shape[1]), dtype=torch.float32).uniform_(0,1).cuda()+1e-8)+1e-8)/args.real_data_tau, dim=1) #0.002  \n",
    "            u_ui += ui_u_sim_detach*args.ui_pre_scale                  \n",
    "            u_ui = F.normalize(u_ui, dim=1)  \n",
    "            inputr = torch.cat((u_ui, u_ui), dim=0)\n",
    "            predr = (self.D(inputr))\n",
    "            lossr = - (predr.mean())\n",
    "            gp = self.gradient_penalty(self.D, inputr, inputf.detach())\n",
    "            loss_D = lossr + lossf + args.gp_rate*gp \n",
    "            self.optim_D.zero_grad()\n",
    "            loss_D.backward()\n",
    "            self.optim_D.step()\n",
    "            line_d_loss.append(loss_D.detach().data)\n",
    "\n",
    "            G_ua_embeddings, G_ia_embeddings, G_image_item_embeds, G_text_item_embeds, G_image_user_embeds, G_text_user_embeds \\\n",
    "                            , G_user_emb, _, G_image_user_id, G_text_user_id, _, _ \\\n",
    "                    = self.model(self.ui_graph, self.iu_graph, self.image_ui_graph, self.image_iu_graph, self.text_ui_graph, self.text_iu_graph)\n",
    "\n",
    "\n",
    "            G_u_g_embeddings = G_ua_embeddings[users]\n",
    "            G_pos_i_g_embeddings = G_ia_embeddings[pos_items]\n",
    "            G_neg_i_g_embeddings = G_ia_embeddings[neg_items]\n",
    "            G_batch_mf_loss, G_batch_emb_loss, G_batch_reg_loss = self.bpr_loss(G_u_g_embeddings, G_pos_i_g_embeddings, G_neg_i_g_embeddings)\n",
    "            G_image_u_sim = self.u_sim_calculation(users, G_image_user_embeds, G_image_item_embeds)\n",
    "            G_text_u_sim = self.u_sim_calculation(users, G_text_user_embeds, G_text_item_embeds)\n",
    "            G_image_u_sim_detach = G_image_u_sim.detach() \n",
    "            G_text_u_sim_detach = G_text_u_sim.detach()\n",
    "\n",
    "\n",
    "            if idx%args.T==0 and idx!=0:\n",
    "                self.image_ui_graph_tmp = csr_matrix((torch.ones(len(self.image_ui_index['x'])),(self.image_ui_index['x'], self.image_ui_index['y'])), shape=(self.n_users, self.n_items))\n",
    "                self.text_ui_graph_tmp = csr_matrix((torch.ones(len(self.text_ui_index['x'])),(self.text_ui_index['x'], self.text_ui_index['y'])), shape=(self.n_users, self.n_items))\n",
    "                self.image_iu_graph_tmp = self.image_ui_graph_tmp.T\n",
    "                self.text_iu_graph_tmp = self.text_ui_graph_tmp.T\n",
    "                self.image_ui_graph = self.sparse_mx_to_torch_sparse_tensor( \\\n",
    "                    self.csr_norm(self.image_ui_graph_tmp, mean_flag=True)\n",
    "                    ).cuda() \n",
    "                self.text_ui_graph = self.sparse_mx_to_torch_sparse_tensor(\n",
    "                    self.csr_norm(self.text_ui_graph_tmp, mean_flag=True)\n",
    "                    ).cuda()\n",
    "                self.image_iu_graph = self.sparse_mx_to_torch_sparse_tensor(\n",
    "                    self.csr_norm(self.image_iu_graph_tmp, mean_flag=True)\n",
    "                    ).cuda()\n",
    "                self.text_iu_graph = self.sparse_mx_to_torch_sparse_tensor(\n",
    "                    self.csr_norm(self.text_iu_graph_tmp, mean_flag=True)\n",
    "                    ).cuda()\n",
    "\n",
    "                self.image_ui_index = {'x':[], 'y':[]}\n",
    "                self.text_ui_index = {'x':[], 'y':[]}\n",
    "\n",
    "            else:\n",
    "                _, image_ui_id = torch.topk(G_image_u_sim_detach, int(self.n_items*args.m_topk_rate), dim=-1)\n",
    "                self.image_ui_index['x'] += np.array(torch.tensor(users).repeat(1, int(self.n_items*args.m_topk_rate)).view(-1)).tolist()\n",
    "                self.image_ui_index['y'] += np.array(image_ui_id.cpu().view(-1)).tolist()\n",
    "                _, text_ui_id = torch.topk(G_text_u_sim_detach, int(self.n_items*args.m_topk_rate), dim=-1)\n",
    "                self.text_ui_index['x'] += np.array(torch.tensor(users).repeat(1, int(self.n_items*args.m_topk_rate)).view(-1)).tolist()\n",
    "                self.text_ui_index['y'] += np.array(text_ui_id.cpu().view(-1)).tolist()\n",
    "\n",
    "\n",
    "            feat_emb_loss = self.feat_reg_loss_calculation(G_image_item_embeds, G_text_item_embeds, G_image_user_embeds, G_text_user_embeds)\n",
    "\n",
    "            batch_contrastive_loss = 0\n",
    "            batch_contrastive_loss1 = self.batched_contrastive_loss(G_image_user_id[users],G_user_emb[users])\n",
    "            batch_contrastive_loss2 = self.batched_contrastive_loss(G_text_user_id[users],G_user_emb[users])\n",
    "\n",
    "            batch_contrastive_loss = batch_contrastive_loss1 + batch_contrastive_loss2 \n",
    "\n",
    "            G_inputf = torch.cat((G_image_u_sim, G_text_u_sim), dim=0)\n",
    "            G_predf = (self.D(G_inputf))\n",
    "\n",
    "            G_lossf = -(G_predf.mean())\n",
    "            batch_loss = G_batch_mf_loss + G_batch_emb_loss + G_batch_reg_loss + feat_emb_loss + args.cl_rate*batch_contrastive_loss + args.G_rate*G_lossf  #feat_emb_loss\n",
    "\n",
    "            line_var_loss.append(batch_loss.detach().data)\n",
    "            line_g_loss.append(G_lossf.detach().data)\n",
    "            line_cl_loss.append(batch_contrastive_loss.detach().data)\n",
    "\n",
    "            loss += float(batch_loss)\n",
    "            mf_loss += float(G_batch_mf_loss)\n",
    "            emb_loss += float(G_batch_emb_loss)\n",
    "            reg_loss += float(G_batch_reg_loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def bpr_loss(self, users, pos_items, neg_items):\n",
    "        pos_scores = torch.sum(torch.mul(users, pos_items), dim=1)\n",
    "        neg_scores = torch.sum(torch.mul(users, neg_items), dim=1)\n",
    "\n",
    "        regularizer = 1./2*(users**2).sum() + 1./2*(pos_items**2).sum() + 1./2*(neg_items**2).sum()        \n",
    "        regularizer = regularizer / self.batch_size\n",
    "\n",
    "        maxi = F.logsigmoid(pos_scores - neg_scores)\n",
    "        mf_loss = -torch.mean(maxi)\n",
    "\n",
    "        emb_loss = self.decay * regularizer\n",
    "        reg_loss = 0.0\n",
    "        return mf_loss, emb_loss, reg_loss\n",
    "\n",
    "    def sparse_mx_to_torch_sparse_tensor(self, sparse_mx):\n",
    "        \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "        sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "        indices = torch.from_numpy(\n",
    "            np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "        values = torch.from_numpy(sparse_mx.data)\n",
    "        shape = torch.Size(sparse_mx.shape)\n",
    "        return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed) \n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n",
    "    set_seed(args.seed)\n",
    "    config = dict()\n",
    "    config['n_users'] = data_generator.n_users\n",
    "    config['n_items'] = data_generator.n_items\n",
    "\n",
    "    trainer = Trainer(data_config=config)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16742bbf-32f8-4ae8-b1dd-0d207c13fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle image 0.2\n",
    "#{'precision': array([0.00613525, 0.00478015, 0.00325534]), 'recall': array([0.0581856 , 0.09064272, 0.15365523]), 'ndcg': array([0.03131403, 0.03982799, 0.05289263]), 'hit_ratio': array([0.06094112, 0.09457444, 0.16050399]), 'auc': 0.0}\n",
    "#shuffle image 0.5\n",
    "#{'precision': array([0.0059244 , 0.00460015, 0.00314322]), 'recall': array([0.05598587, 0.08734232, 0.14823411]), 'ndcg': array([0.03014553, 0.03830779, 0.05098226]), 'hit_ratio': array([0.05878118, 0.09123168, 0.15443559]), 'auc': 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb006d6-6ee5-4634-bba5-bc5513d99980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle all 0.2\n",
    "#{'precision': array([0.0059244 , 0.00464644, 0.00319259, 0.00744664]), 'recall': array([0.05599138, 0.08787973, 0.1509533 , 0.03531377]), 'ndcg': array([0.03049136, 0.03891664, 0.05194823, 0.0235323 ]), 'hit_ratio': array([0.05878118, 0.09200309, 0.15746979, 0.03713037]), 'mrr': array([0.02226298, 0.02454933, 0.02658688, 0.01941287]), 'auc': 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73c3c77-2484-47d4-a01e-8454bc210961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "headers = {\"Authorization\": \"eyJhbGciOiJFUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1aWQiOjQwMTY2LCJ1dWlkIjoiNmE1MGYzN2ItNTE1My00ZGY4LTkzZjYtZTJkNGRkZjhhMWM1IiwiaXNfYWRtaW4iOmZhbHNlLCJpc19zdXBlcl9hZG1pbiI6ZmFsc2UsInN1Yl9uYW1lIjoiIiwidGVuYW50IjoiYXV0b2RsIiwidXBrIjoiIn0.W9vekL_TuPpETo5tcNnSNn4lRLPj8znhZ7T4yFxDaKmpJIY4kLNN-RqKPHw0wZtYTZDoVE-QMlSW3Gem7Wi6Ww\"}\n",
    "resp = requests.post(\"https://www.autodl.com/api/v1/wechat/message/send\",\n",
    "                     json={\n",
    "                         \"title\": \"my_clip_rob-best-try\",\n",
    "                         \"name\": \"my_clip_rob-best-try\",\n",
    "                         \"content\": \"my_clip_rob-best-try\"\n",
    "                     }, headers = headers)\n",
    "print(resp.content.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c437482d-993e-46c3-8607-16afcce08433",
   "metadata": {},
   "outputs": [],
   "source": [
    "!shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3468957-d72d-43c9-a61f-f69c8ce7ece2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
